{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detección de Mascarillas: CNN Personalizada y Transfer Learning\n",
    "\n",
    "**Análisis y Comparación de Arquitecturas para la Localización de Objetos**\n",
    "\n",
    "Este notebook aborda el problema de la detección de mascarillas a través de dos enfoques principales:\n",
    "1.  **CNN Personalizada:** Se diseña, entrena y evalúa una Red Neuronal Convolucional desde cero.\n",
    "2.  **Transfer Learning:** Se adaptan dos modelos pre-entrenados (EfficientNet-B0 y Swin Transformer V2) para la misma tarea.\n",
    "\n",
    "Se explorará el impacto del **aumento de datos** y el ajuste de **hiperparámetros** como el learning rate y el optimizador para mejorar el rendimiento en la clasificación y la regresión del cuadro delimitador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando el dispositivo: cuda\n"
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# CONFIGURACIÓN INICIAL\n",
    "# ===========================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.optim import Optimizer\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchsummary import summary\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import os\n",
    "import os.path as osp\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import typing as ty\n",
    "import copy\n",
    "from functools import reduce\n",
    "\n",
    "# Ignorar advertencias para una salida más limpia\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración de reproducibilidad y dispositivo\n",
    "torch.manual_seed(42)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Usando el dispositivo: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estructura del DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>class</th>\n",
       "      <th>class_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>video_CDC-YOUTUBE_mp4-63_jpg.rf.2f4f64f6ef712f...</td>\n",
       "      <td>315</td>\n",
       "      <td>249</td>\n",
       "      <td>468</td>\n",
       "      <td>374</td>\n",
       "      <td>no-mask</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMG_4860_mp4-36_jpg.rf.01a053cabddff2cdd19f04e...</td>\n",
       "      <td>257</td>\n",
       "      <td>237</td>\n",
       "      <td>299</td>\n",
       "      <td>264</td>\n",
       "      <td>no-mask</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMG_1491_mp4-12_jpg.rf.9df64033aebef44b8bb9a6a...</td>\n",
       "      <td>291</td>\n",
       "      <td>245</td>\n",
       "      <td>582</td>\n",
       "      <td>449</td>\n",
       "      <td>mask</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMG_4861_mp4-64_jpg.rf.74ab6d1da8a1fa9b8fbb576...</td>\n",
       "      <td>231</td>\n",
       "      <td>229</td>\n",
       "      <td>577</td>\n",
       "      <td>420</td>\n",
       "      <td>no-mask</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IMG_9950-1-_mp4-83_jpg.rf.74dca33810c23ba144d8...</td>\n",
       "      <td>107</td>\n",
       "      <td>168</td>\n",
       "      <td>515</td>\n",
       "      <td>469</td>\n",
       "      <td>no-mask</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  xmin  ymin  xmax  ymax  \\\n",
       "0  video_CDC-YOUTUBE_mp4-63_jpg.rf.2f4f64f6ef712f...   315   249   468   374   \n",
       "1  IMG_4860_mp4-36_jpg.rf.01a053cabddff2cdd19f04e...   257   237   299   264   \n",
       "2  IMG_1491_mp4-12_jpg.rf.9df64033aebef44b8bb9a6a...   291   245   582   449   \n",
       "3  IMG_4861_mp4-64_jpg.rf.74ab6d1da8a1fa9b8fbb576...   231   229   577   420   \n",
       "4  IMG_9950-1-_mp4-83_jpg.rf.74dca33810c23ba144d8...   107   168   515   469   \n",
       "\n",
       "     class  class_id  \n",
       "0  no-mask         0  \n",
       "1  no-mask         0  \n",
       "2     mask         1  \n",
       "3  no-mask         0  \n",
       "4  no-mask         0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===========================\n",
    "# CARGA Y PREPARACIÓN DE DATOS\n",
    "# ===========================\n",
    "\n",
    "# Rutas de los directorios\n",
    "DATA_DIR = './kaggle/input/aa-iv-2025-ii-object-localization'\n",
    "IMG_DIR = osp.join(DATA_DIR, \"images\")\n",
    "\n",
    "# Carga del archivo de anotaciones\n",
    "df = pd.read_csv(osp.join(DATA_DIR, \"train.csv\"))\n",
    "\n",
    "# Mapeo de clases a IDs numéricos y viceversa\n",
    "obj2id = {'no-mask': 0, 'mask': 1}\n",
    "id2obj = {0: 'no-mask', 1: 'mask'}\n",
    "\n",
    "df[\"class_id\"] = df[\"class\"].map(obj2id)\n",
    "\n",
    "# Selección de columnas relevantes\n",
    "df = df[['filename', 'xmin', 'ymin', 'xmax', 'ymax', 'class', 'class_id']].copy()\n",
    "\n",
    "print(\"Estructura del DataFrame:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de entrenamiento: 175 muestras\n",
      "Tamaño del conjunto de validación: 44 muestras\n"
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# PREPROCESAMIENTO\n",
    "# ===========================\n",
    "\n",
    "# Normalización de las coordenadas del Bounding Box\n",
    "h_real, w_real = 640, 640  # Dimensiones de las imágenes\n",
    "df[[\"ymin\", \"ymax\"]] = df[[\"ymin\", \"ymax\"]].div(h_real, axis=0)\n",
    "df[[\"xmin\", \"xmax\"]] = df[[\"xmin\", \"xmax\"]].div(w_real, axis=0)\n",
    "\n",
    "# División estratificada en conjuntos de entrenamiento y validación\n",
    "train_df, val_df = train_test_split(\n",
    "    df,\n",
    "    stratify=df['class_id'],\n",
    "    test_size=0.20, # 20% para validación\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Tamaño del conjunto de entrenamiento: {train_df.shape[0]} muestras\")\n",
    "print(f\"Tamaño del conjunto de validación: {val_df.shape[0]} muestras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# CLASE DATASET DE PYTORCH (CORREGIDA V2)\n",
    "# ===========================\n",
    "\n",
    "class MaskDataset(Dataset):\n",
    "    \"\"\"Dataset para cargar las imágenes, bounding boxes y clases.\"\"\"\n",
    "    def __init__(self, df: pd.DataFrame, root_dir: str, transform=None, labeled: bool = True):\n",
    "        self.df = df\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.labeled = labeled\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        # Cargar imagen\n",
    "        img_name = os.path.join(self.root_dir, self.df.filename.iloc[idx])\n",
    "        image = cv2.imread(img_name)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        sample = {'image': image}\n",
    "\n",
    "        if self.labeled:\n",
    "            bbox = self.df.iloc[idx, 1:5].values.astype('float')\n",
    "            class_id = self.df.class_id.iloc[idx]\n",
    "            sample.update({'bbox': np.array([bbox]), 'class_id': np.array([class_id])})\n",
    "\n",
    "        if self.transform:\n",
    "            transform_args = {'image': sample['image']}\n",
    "            if self.labeled:\n",
    "                transform_args['bboxes'] = sample['bbox']\n",
    "                transform_args['category_ids'] = [sample['class_id'].item()]\n",
    "            \n",
    "            transformed = self.transform(**transform_args)\n",
    "            \n",
    "            sample['image'] = transformed['image']\n",
    "            if self.labeled:\n",
    "                # === INICIO DE LA CORRECCIÓN ===\n",
    "                # Comprobamos la longitud del contenedor para ver si hay bboxes,\n",
    "                # en lugar de evaluar la \"veracidad\" del array.\n",
    "                if len(transformed['bboxes']) > 0:\n",
    "                    # Albumentations devuelve una tupla por bbox, tomamos solo las coordenadas.\n",
    "                    bbox_coords = transformed['bboxes'][0][:4]\n",
    "                    sample['bbox'] = torch.tensor(bbox_coords, dtype=torch.float32)\n",
    "                else:\n",
    "                    # Si el aumento de datos eliminó el bbox, creamos un tensor vacío.\n",
    "                    sample['bbox'] = torch.zeros(4, dtype=torch.float32)\n",
    "                # === FIN DE LA CORRECCIÓN ===\n",
    "        \n",
    "        # Convertir imagen a tensor y permutar dimensiones (H,W,C) -> (C,H,W)\n",
    "        sample['image'] = torch.from_numpy(sample['image'].transpose((2, 0, 1))).float()\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aumento de Datos (Data Augmentation)\n",
    "\n",
    "Se definen tres niveles de aumento de datos para comparar su impacto:\n",
    "\n",
    "1.  **Aumento Ligero (`light_augmentations`):**\n",
    "    *   `HorizontalFlip`: La técnica más común y segura. Refleja la imagen horizontalmente, lo cual es una variación muy probable en escenarios reales (personas vistas de izquierda o derecha). Ayuda al modelo a ser invariante a la orientación.\n",
    "\n",
    "2.  **Aumento Medio (`medium_augmentations`):**\n",
    "    *   Incluye el `HorizontalFlip`.\n",
    "    *   `RandomBrightnessContrast`: Simula diferentes condiciones de iluminación. Es útil porque las fotos pueden ser tomadas en interiores, exteriores, con o sin flash. Entrena al modelo para que no dependa del brillo o contraste específico de la imagen.\n",
    "    *   `Rotate`: Introduce pequeñas rotaciones. Las cabezas de las personas no siempre están perfectamente verticales. Esto ayuda al modelo a reconocer objetos aunque estén ligeramente inclinados.\n",
    "\n",
    "3.  **Aumento Pesado (`heavy_augmentations`):**\n",
    "    *   Incluye las transformaciones anteriores.\n",
    "    *   `Blur`: Simula imágenes ligeramente desenfocadas o con movimiento, lo que puede ocurrir con cámaras de baja calidad o movimiento rápido.\n",
    "    *   `CoarseDropout`: Elimina regiones rectangulares de la imagen, forzando al modelo a aprender de características parciales del objeto y a no depender de una sola región específica (como los ojos o la nariz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# PIPELINES DE AUMENTO DE DATOS\n",
    "# ===========================\n",
    "IMG_SIZE = 256 # Tamaño de entrada para los modelos\n",
    "\n",
    "# Parámetros comunes para los bounding boxes en Albumentations\n",
    "BBOX_PARAMS = A.BboxParams(format='albumentations', label_fields=['category_ids'])\n",
    "\n",
    "# 1. Aumento Ligero\n",
    "light_augmentations = A.Compose([\n",
    "    A.Resize(IMG_SIZE, IMG_SIZE),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "], bbox_params=BBOX_PARAMS)\n",
    "\n",
    "# 2. Aumento Medio\n",
    "medium_augmentations = A.Compose([\n",
    "    A.Resize(IMG_SIZE, IMG_SIZE),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.3),\n",
    "    A.Rotate(limit=15, p=0.4),\n",
    "], bbox_params=BBOX_PARAMS)\n",
    "\n",
    "# 3. Aumento Pesado\n",
    "heavy_augmentations = A.Compose([\n",
    "    A.Resize(IMG_SIZE, IMG_SIZE),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.4),\n",
    "    A.Rotate(limit=20, p=0.5),\n",
    "    A.Blur(blur_limit=3, p=0.2),\n",
    "    A.CoarseDropout(max_holes=8, max_height=16, max_width=16, p=0.3),\n",
    "], bbox_params=BBOX_PARAMS)\n",
    "\n",
    "# Transformaciones solo para validación (sin aumento)\n",
    "val_transforms = A.Compose([\n",
    "    A.Resize(IMG_SIZE, IMG_SIZE),\n",
    "], bbox_params=BBOX_PARAMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de Modelos\n",
    "\n",
    "### 1. Backbone: CNN Personalizada\n",
    "Se crea una CNN simple desde cero que servirá como extractor de características. Consta de tres bloques convolucionales, cada uno con una capa `Conv2d`, `ReLU` para la activación y `MaxPool2d` para reducir las dimensiones espaciales. Finalmente, un `AdaptiveAvgPool2d` asegura que la salida tenga un tamaño fijo antes de pasar a las cabezas.\n",
    "\n",
    "### 2. Cabezas de Clasificación y Regresión\n",
    "La clase `Model` es un módulo genérico que integra un `backbone` con dos cabezas:\n",
    "- **Cabeza de Clasificación (`cls_head`):** Una red neuronal simple (MLP) que toma las características del backbone y predice la probabilidad de cada clase (`mask` o `no-mask`).\n",
    "- **Cabeza de Regresión (`reg_head`):** Otro MLP que predice las 4 coordenadas del bounding box (`xmin`, `ymin`, `xmax`, `ymax`).\n",
    "\n",
    "Esta estructura modular permite intercambiar fácilmente el backbone (CNN personalizada, EfficientNet, Swin Transformer).\n",
    "\n",
    "### 3. Backbones para Transfer Learning\n",
    "- **EfficientNet-B0:** Un modelo ligero y eficiente, conocido por su buen equilibrio entre precisión y costo computacional.\n",
    "- **Swin Transformer V2:** Un modelo basado en la arquitectura Transformer, que ha demostrado un rendimiento excelente en tareas de visión por computadora al capturar dependencias a larga distancia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================\n",
    "# 1. BACKBONE: CNN PERSONALIZADA\n",
    "# ===============================================\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self, output_features_dim=256):\n",
    "        super().__init__()\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2) # 256 -> 128\n",
    "        )\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2) # 128 -> 64\n",
    "        )\n",
    "        self.conv_block3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2) # 64 -> 32\n",
    "        )\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.final_layer = nn.Linear(128, output_features_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.conv_block3(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.final_layer(x)\n",
    "        return x\n",
    "\n",
    "# ===============================================\n",
    "# 2. CABEZAS DE CLASIFICACIÓN Y REGRESIÓN\n",
    "# ===============================================\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, backbone: nn.Module, backbone_out_features: int, n_classes: int = 2):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "\n",
    "        # Cabeza de Regresión\n",
    "        self.reg_head = nn.Sequential(\n",
    "            nn.Linear(backbone_out_features, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 4) # 4 coordenadas del bbox\n",
    "        )\n",
    "\n",
    "        # Cabeza de Clasificación\n",
    "        self.cls_head = nn.Sequential(\n",
    "            nn.Linear(backbone_out_features, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, n_classes) # 2 clases\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor) -> ty.Dict[str, Tensor]:\n",
    "        features = self.backbone(x)\n",
    "        pred_bbox = self.reg_head(features)\n",
    "        cls_logits = self.cls_head(features)\n",
    "        return {'bbox': pred_bbox, 'class_id': cls_logits}\n",
    "\n",
    "# ===============================================\n",
    "# 3. BACKBONES PRE-ENTRENADOS\n",
    "# ===============================================\n",
    "class EffNetFeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        m = torchvision.models.efficientnet_b0(weights='DEFAULT')\n",
    "        self.features = m.features\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "        return x\n",
    "\n",
    "class SwinV2FeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        m = torchvision.models.swin_v2_b(weights='DEFAULT')\n",
    "        self.features = m.features\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# FUNCIONES AUXILIARES\n",
    "# ===========================\n",
    "\n",
    "def iou(y_true: Tensor, y_pred: Tensor):\n",
    "    \"\"\"Calcula la métrica IoU (Intersection over Union).\"\"\"\n",
    "    # torchvision.ops.box_iou espera [N, 4] y [M, 4]\n",
    "    if y_true.dim() == 3: y_true = y_true.squeeze(1)\n",
    "    if y_pred.dim() == 3: y_pred = y_pred.squeeze(1)\n",
    "    pairwise_iou = torchvision.ops.box_iou(y_true, y_pred)\n",
    "    # Tomamos la diagonal, asumiendo una correspondencia 1 a 1\n",
    "    result = torch.diag(pairwise_iou).mean()\n",
    "    return result\n",
    "\n",
    "def accuracy(y_true: Tensor, y_pred: Tensor):\n",
    "    \"\"\"Calcula la métrica de Accuracy para clasificación.\"\"\"\n",
    "    y_true = y_true.squeeze().long()\n",
    "    pred = torch.argmax(y_pred, dim=-1)\n",
    "    return (pred == y_true).float().mean()\n",
    "\n",
    "def loss_fn(y_true, y_preds, alpha=0.5):\n",
    "    \"\"\"Función de pérdida combinada para clasificación y regresión.\"\"\"\n",
    "    # Pérdida de clasificación (Cross Entropy)\n",
    "    cls_y_true = y_true['class_id'].squeeze().long()\n",
    "    cls_loss = F.cross_entropy(y_preds['class_id'], cls_y_true)\n",
    "\n",
    "    # Pérdida de regresión (Smooth L1 Loss es más robusta a outliers que MSE)\n",
    "    reg_loss = F.smooth_l1_loss(y_preds['bbox'], y_true['bbox'])\n",
    "\n",
    "    total_loss = (1 - alpha) * cls_loss + alpha * reg_loss\n",
    "    return {'loss': total_loss, 'reg_loss': reg_loss, 'cls_loss': cls_loss}\n",
    "\n",
    "def train_one_epoch(model, dataloader, optimizer, device):\n",
    "    \"\"\"Bucle de entrenamiento para una época.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    pbar = tqdm(dataloader, desc=\"Entrenando\")\n",
    "    for batch in pbar:\n",
    "        optimizer.zero_grad()\n",
    "        # Mover datos al dispositivo\n",
    "        for key in ['image', 'bbox', 'class_id']:\n",
    "            batch[key] = batch[key].to(device)\n",
    "\n",
    "        preds = model(batch['image'])\n",
    "        losses = loss_fn(batch, preds)\n",
    "        losses['loss'].backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += losses['loss'].item()\n",
    "        pbar.set_postfix(loss=total_loss/len(pbar))\n",
    "\n",
    "def evaluate(model, dataloader, device):\n",
    "    \"\"\"Bucle de evaluación.\"\"\"\n",
    "    model.eval()\n",
    "    total_cls_loss, total_reg_loss = 0, 0\n",
    "    all_acc, all_iou = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluando\"):\n",
    "            for key in ['image', 'bbox', 'class_id']:\n",
    "                batch[key] = batch[key].to(device)\n",
    "\n",
    "            preds = model(batch['image'])\n",
    "            losses = loss_fn(batch, preds)\n",
    "            total_cls_loss += losses['cls_loss'].item()\n",
    "            total_reg_loss += losses['reg_loss'].item()\n",
    "\n",
    "            all_acc.append(accuracy(batch['class_id'], preds['class_id']).cpu())\n",
    "            all_iou.append(iou(batch['bbox'], preds['bbox']).cpu())\n",
    "\n",
    "    avg_acc = np.mean(all_acc)\n",
    "    avg_iou = np.mean(all_iou)\n",
    "    print(f\"Resultados de validación -> Accuracy: {avg_acc:.4f}, IoU: {avg_iou:.4f}\")\n",
    "    return avg_iou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimento 1: CNN Personalizada con Diferentes Aumentos de Datos\n",
    "\n",
    "En este experimento, entrenaremos el modelo con el backbone de CNN personalizada desde cero. El objetivo es analizar cómo los diferentes niveles de aumento de datos (`light`, `medium`, `heavy`) afectan el rendimiento del modelo en ambas tareas (clasificación y regresión)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Entrenando con aumento de datos: LIGHT ---\n",
      "Época 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando: 100%|██████████| 6/6 [00:05<00:00,  1.06it/s, loss=0.563]\n",
      "Evaluando: 100%|██████████| 2/2 [00:00<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de validación -> Accuracy: 0.5781, IoU: 0.1434\n",
      "Nuevo mejor modelo de CNN personalizada con IoU: 0.1434\n",
      "Época 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando: 100%|██████████| 6/6 [00:05<00:00,  1.09it/s, loss=0.362] \n",
      "Evaluando: 100%|██████████| 2/2 [00:00<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de validación -> Accuracy: 0.5781, IoU: 0.1552\n",
      "Nuevo mejor modelo de CNN personalizada con IoU: 0.1552\n",
      "Época 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando: 100%|██████████| 6/6 [00:05<00:00,  1.12it/s, loss=0.351]\n",
      "Evaluando: 100%|██████████| 2/2 [00:00<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de validación -> Accuracy: 0.5781, IoU: 0.2305\n",
      "Nuevo mejor modelo de CNN personalizada con IoU: 0.2305\n",
      "Época 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando: 100%|██████████| 6/6 [00:05<00:00,  1.15it/s, loss=0.347] \n",
      "Evaluando: 100%|██████████| 2/2 [00:00<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de validación -> Accuracy: 0.5781, IoU: 0.2226\n",
      "Época 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando: 100%|██████████| 6/6 [00:05<00:00,  1.18it/s, loss=0.341] \n",
      "Evaluando: 100%|██████████| 2/2 [00:00<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de validación -> Accuracy: 0.5781, IoU: 0.1595\n",
      "\n",
      "--- Entrenando con aumento de datos: MEDIUM ---\n",
      "Época 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando: 100%|██████████| 6/6 [00:05<00:00,  1.14it/s, loss=0.636]\n",
      "Evaluando: 100%|██████████| 2/2 [00:00<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de validación -> Accuracy: 0.5781, IoU: 0.0333\n",
      "Época 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando: 100%|██████████| 6/6 [00:05<00:00,  1.14it/s, loss=0.357] \n",
      "Evaluando: 100%|██████████| 2/2 [00:00<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de validación -> Accuracy: 0.6615, IoU: 0.1402\n",
      "Época 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando: 100%|██████████| 6/6 [00:05<00:00,  1.14it/s, loss=0.354] \n",
      "Evaluando: 100%|██████████| 2/2 [00:00<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de validación -> Accuracy: 0.5781, IoU: 0.2132\n",
      "Época 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando: 100%|██████████| 6/6 [00:05<00:00,  1.15it/s, loss=0.349]\n",
      "Evaluando: 100%|██████████| 2/2 [00:00<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de validación -> Accuracy: 0.5781, IoU: 0.2378\n",
      "Nuevo mejor modelo de CNN personalizada con IoU: 0.2378\n",
      "Época 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando: 100%|██████████| 6/6 [00:05<00:00,  1.14it/s, loss=0.346] \n",
      "Evaluando: 100%|██████████| 2/2 [00:00<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de validación -> Accuracy: 0.5781, IoU: 0.2522\n",
      "Nuevo mejor modelo de CNN personalizada con IoU: 0.2522\n",
      "\n",
      "--- Entrenando con aumento de datos: HEAVY ---\n",
      "Época 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando: 100%|██████████| 6/6 [00:05<00:00,  1.12it/s, loss=0.957]\n",
      "Evaluando: 100%|██████████| 2/2 [00:00<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de validación -> Accuracy: 0.5781, IoU: 0.0000\n",
      "Época 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando: 100%|██████████| 6/6 [00:05<00:00,  1.13it/s, loss=0.417] \n",
      "Evaluando: 100%|██████████| 2/2 [00:00<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de validación -> Accuracy: 0.4219, IoU: 0.1869\n",
      "Época 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando: 100%|██████████| 6/6 [00:05<00:00,  1.14it/s, loss=0.355] \n",
      "Evaluando: 100%|██████████| 2/2 [00:00<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de validación -> Accuracy: 0.5781, IoU: 0.2365\n",
      "Época 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando: 100%|██████████| 6/6 [00:05<00:00,  1.15it/s, loss=0.352] \n",
      "Evaluando: 100%|██████████| 2/2 [00:00<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de validación -> Accuracy: 0.5781, IoU: 0.1921\n",
      "Época 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando: 100%|██████████| 6/6 [00:05<00:00,  1.15it/s, loss=0.347] \n",
      "Evaluando: 100%|██████████| 2/2 [00:00<00:00,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de validación -> Accuracy: 0.5781, IoU: 0.2411\n",
      "\n",
      "Mejor modelo de CNN personalizada guardado.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# EXPERIMENTO 1: CNN PERSONALIZADA + COMPARACIÓN DE AUMENTO DE DATOS\n",
    "# ================================================================\n",
    "EPOCHS = 5\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "augmentation_pipelines = {\n",
    "    \"light\": light_augmentations,\n",
    "    \"medium\": medium_augmentations,\n",
    "    \"heavy\": heavy_augmentations\n",
    "}\n",
    "\n",
    "best_custom_cnn_model = None\n",
    "best_custom_cnn_iou = -1\n",
    "\n",
    "for name, aug_pipeline in augmentation_pipelines.items():\n",
    "    print(f\"\\n--- Entrenando con aumento de datos: {name.upper()} ---\")\n",
    "\n",
    "    # 1. Crear Datasets y DataLoaders\n",
    "    # Aseguramos que las variables se creen de nuevo en cada iteración\n",
    "    train_dataset_custom = MaskDataset(train_df, root_dir=IMG_DIR, transform=aug_pipeline)\n",
    "    val_dataset_custom = MaskDataset(val_df, root_dir=IMG_DIR, transform=val_transforms)\n",
    "\n",
    "    train_loader_custom = DataLoader(train_dataset_custom, batch_size=32, shuffle=True)\n",
    "    val_loader_custom = DataLoader(val_dataset_custom, batch_size=32, shuffle=False)\n",
    "\n",
    "    # 2. Instanciar el modelo (siempre uno nuevo)\n",
    "    backbone_custom = CustomCNN(output_features_dim=128).to(device)\n",
    "    model_custom = Model(backbone=backbone_custom, backbone_out_features=128).to(device)\n",
    "    optimizer_custom = torch.optim.Adam(model_custom.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    # 3. Bucle de entrenamiento\n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"Época {epoch + 1}/{EPOCHS}\")\n",
    "        train_one_epoch(model_custom, train_loader_custom, optimizer_custom, device)\n",
    "        current_iou = evaluate(model_custom, val_loader_custom, device)\n",
    "\n",
    "        # Guardar el mejor modelo de este experimento\n",
    "        if current_iou > best_custom_cnn_iou:\n",
    "            best_custom_cnn_iou = current_iou\n",
    "            best_custom_cnn_model = copy.deepcopy(model_custom.state_dict())\n",
    "            print(f\"Nuevo mejor modelo de CNN personalizada con IoU: {best_custom_cnn_iou:.4f}\")\n",
    "\n",
    "# Guardar el mejor modelo de la CNN personalizada en disco\n",
    "torch.save(best_custom_cnn_model, 'custom_cnn_best.pth')\n",
    "print(\"\\nMejor modelo de CNN personalizada guardado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimento 2: Transfer Learning\n",
    "\n",
    "Ahora, utilizaremos modelos pre-entrenados como backbones, conectando nuestras cabezas de clasificación y regresión.\n",
    "\n",
    "### 2.1 EfficientNet-B0: Ajuste del Learning Rate\n",
    "Probaremos tres tasas de aprendizaje (`1e-3`, `1e-4`, `1e-5`) para encontrar la que mejor se adapte a la tarea de fine-tuning con EfficientNet. Un learning rate más bajo suele ser preferible para no destruir las características aprendidas por el modelo pre-entrenado.\n",
    "\n",
    "### 2.2 Swin Transformer V2: Ajuste del Optimizador y Weight Decay\n",
    "Para el Swin Transformer, compararemos dos optimizadores:\n",
    "- **Adam:** Un optimizador estándar y robusto.\n",
    "- **AdamW:** Una variante de Adam que desacopla la regularización de `weight_decay` de la actualización del gradiente, lo que a menudo conduce a una mejor generalización.\n",
    "Además, probaremos dos valores de `weight_decay` (`1e-4` y `1e-2`) para analizar el efecto de la regularización L2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Entrenando EfficientNet-B0 con LR: 0.001 ---\n",
      "Época 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando: 100%|██████████| 11/11 [00:13<00:00,  1.22s/it, loss=0.26] \n",
      "Evaluando: 100%|██████████| 3/3 [00:00<00:00,  4.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de validación -> Accuracy: 0.7708, IoU: 0.0841\n",
      "Nuevo mejor modelo EfficientNet con IoU: 0.0841\n",
      "Época 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando: 100%|██████████| 11/11 [00:13<00:00,  1.21s/it, loss=0.0781]\n",
      "Evaluando: 100%|██████████| 3/3 [00:00<00:00,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de validación -> Accuracy: 0.9306, IoU: 0.1631\n",
      "Nuevo mejor modelo EfficientNet con IoU: 0.1631\n",
      "Época 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando: 100%|██████████| 11/11 [00:13<00:00,  1.21s/it, loss=0.0403]\n",
      "Evaluando: 100%|██████████| 3/3 [00:00<00:00,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de validación -> Accuracy: 0.9306, IoU: 0.1560\n",
      "\n",
      "--- Entrenando EfficientNet-B0 con LR: 0.0001 ---\n",
      "Época 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando: 100%|██████████| 11/11 [00:13<00:00,  1.20s/it, loss=0.377]\n",
      "Evaluando: 100%|██████████| 3/3 [00:00<00:00,  4.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de validación -> Accuracy: 0.7708, IoU: 0.0056\n",
      "Época 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando: 100%|██████████| 11/11 [00:13<00:00,  1.22s/it, loss=0.271]\n",
      "Evaluando: 100%|██████████| 3/3 [00:00<00:00,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de validación -> Accuracy: 0.8542, IoU: 0.1176\n",
      "Época 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando: 100%|██████████| 11/11 [00:13<00:00,  1.21s/it, loss=0.19] \n",
      "Evaluando: 100%|██████████| 3/3 [00:00<00:00,  4.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de validación -> Accuracy: 0.8889, IoU: 0.1737\n",
      "Nuevo mejor modelo EfficientNet con IoU: 0.1737\n",
      "\n",
      "--- Entrenando EfficientNet-B0 con LR: 1e-05 ---\n",
      "Época 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando: 100%|██████████| 11/11 [00:13<00:00,  1.21s/it, loss=0.408]\n",
      "Evaluando: 100%|██████████| 3/3 [00:00<00:00,  4.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de validación -> Accuracy: 0.3819, IoU: 0.0000\n",
      "Época 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando: 100%|██████████| 11/11 [00:13<00:00,  1.21s/it, loss=0.392]\n",
      "Evaluando: 100%|██████████| 3/3 [00:00<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de validación -> Accuracy: 0.6944, IoU: 0.0000\n",
      "Época 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando: 100%|██████████| 11/11 [00:13<00:00,  1.21s/it, loss=0.378]\n",
      "Evaluando: 100%|██████████| 3/3 [00:00<00:00,  4.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de validación -> Accuracy: 0.8403, IoU: 0.0000\n",
      "\n",
      "Mejor modelo EfficientNet guardado.\n",
      "\n",
      "--- Entrenando Swin Transformer con Optimizador: Adam (wd=0.0001) ---\n",
      "Época 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando: 100%|██████████| 11/11 [02:31<00:00, 13.79s/it, loss=0.491]\n",
      "Evaluando: 100%|██████████| 3/3 [00:13<00:00,  4.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de validación -> Accuracy: 0.6042, IoU: 0.0013\n",
      "Nuevo mejor modelo Swin Transformer con IoU: 0.0013\n",
      "Época 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando: 100%|██████████| 11/11 [02:32<00:00, 13.82s/it, loss=0.4]  \n",
      "Evaluando: 100%|██████████| 3/3 [00:13<00:00,  4.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de validación -> Accuracy: 0.5833, IoU: 0.0165\n",
      "Nuevo mejor modelo Swin Transformer con IoU: 0.0165\n",
      "Época 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando: 100%|██████████| 11/11 [02:31<00:00, 13.80s/it, loss=0.367]\n",
      "Evaluando: 100%|██████████| 3/3 [00:13<00:00,  4.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de validación -> Accuracy: 0.6944, IoU: 0.0473\n",
      "Nuevo mejor modelo Swin Transformer con IoU: 0.0473\n",
      "\n",
      "--- Entrenando Swin Transformer con Optimizador: AdamW (wd=0.0001) ---\n",
      "Época 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando: 100%|██████████| 11/11 [03:05<00:00, 16.89s/it, loss=0.468]\n",
      "Evaluando: 100%|██████████| 3/3 [00:16<00:00,  5.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de validación -> Accuracy: 0.6042, IoU: 0.0002\n",
      "Época 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando: 100%|██████████| 11/11 [03:07<00:00, 17.02s/it, loss=0.374]\n",
      "Evaluando: 100%|██████████| 3/3 [00:16<00:00,  5.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de validación -> Accuracy: 0.6042, IoU: 0.0138\n",
      "Época 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando: 100%|██████████| 11/11 [03:05<00:00, 16.86s/it, loss=0.357]\n",
      "Evaluando: 100%|██████████| 3/3 [00:16<00:00,  5.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de validación -> Accuracy: 0.6042, IoU: 0.0827\n",
      "Nuevo mejor modelo Swin Transformer con IoU: 0.0827\n",
      "\n",
      "--- Entrenando Swin Transformer con Optimizador: AdamW_high_wd (wd=0.01) ---\n",
      "Época 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando: 100%|██████████| 11/11 [03:19<00:00, 18.12s/it, loss=0.547]\n",
      "Evaluando: 100%|██████████| 3/3 [00:19<00:00,  6.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de validación -> Accuracy: 0.6042, IoU: 0.0000\n",
      "Época 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando: 100%|██████████| 11/11 [03:10<00:00, 17.29s/it, loss=0.399]\n",
      "Evaluando: 100%|██████████| 3/3 [00:18<00:00,  6.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de validación -> Accuracy: 0.6042, IoU: 0.0287\n",
      "Época 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando: 100%|██████████| 11/11 [03:09<00:00, 17.24s/it, loss=0.357]\n",
      "Evaluando: 100%|██████████| 3/3 [00:18<00:00,  6.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de validación -> Accuracy: 0.6042, IoU: 0.1335\n",
      "Nuevo mejor modelo Swin Transformer con IoU: 0.1335\n",
      "\n",
      "Mejor modelo Swin Transformer guardado.\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# EXPERIMENTO 2.1: EFFICIENTNET-B0 + AJUSTE DE LEARNING RATE\n",
    "# ================================================================\n",
    "EPOCHS = 10\n",
    "learning_rates = [1e-3, 1e-4, 1e-5]\n",
    "\n",
    "best_effnet_model = None\n",
    "best_effnet_iou = -1\n",
    "\n",
    "train_dataset_tl = MaskDataset(train_df, root_dir=IMG_DIR, transform=medium_augmentations)\n",
    "val_dataset_tl = MaskDataset(val_df, root_dir=IMG_DIR, transform=val_transforms)\n",
    "train_loader_tl = DataLoader(train_dataset_tl, batch_size=16, shuffle=True)\n",
    "val_loader_tl = DataLoader(val_dataset_tl, batch_size=16, shuffle=False)\n",
    "\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\n--- Entrenando EfficientNet-B0 con LR: {lr} ---\")\n",
    "\n",
    "    backbone_effnet = EffNetFeatureExtractor().to(device)\n",
    "    model_effnet = Model(backbone=backbone_effnet, backbone_out_features=1280).to(device)\n",
    "    optimizer_effnet = torch.optim.Adam(model_effnet.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"Época {epoch + 1}/{EPOCHS}\")\n",
    "        train_one_epoch(model_effnet, train_loader_tl, optimizer_effnet, device)\n",
    "        current_iou = evaluate(model_effnet, val_loader_tl, device)\n",
    "\n",
    "        if current_iou > best_effnet_iou:\n",
    "            best_effnet_iou = current_iou\n",
    "            best_effnet_model = copy.deepcopy(model_effnet.state_dict())\n",
    "            print(f\"Nuevo mejor modelo EfficientNet con IoU: {best_effnet_iou:.4f}\")\n",
    "\n",
    "torch.save(best_effnet_model, 'efficientnet_best.pth')\n",
    "print(\"\\nMejor modelo EfficientNet guardado.\")\n",
    "\n",
    "# ================================================================\n",
    "# EXPERIMENTO 2.2: SWIN TRANSFORMER + AJUSTE DE OPTIMIZADOR\n",
    "# ================================================================\n",
    "optimizers_config = [\n",
    "    {\"name\": \"Adam\", \"optim\": torch.optim.Adam, \"wd\": 1e-4},\n",
    "    {\"name\": \"AdamW\", \"optim\": torch.optim.AdamW, \"wd\": 1e-4},\n",
    "    {\"name\": \"AdamW_high_wd\", \"optim\": torch.optim.AdamW, \"wd\": 1e-2},\n",
    "]\n",
    "\n",
    "best_swin_model = None\n",
    "best_swin_iou = -1\n",
    "LEARNING_RATE_SWIN = 1e-5\n",
    "\n",
    "for config in optimizers_config:\n",
    "    print(f\"\\n--- Entrenando Swin Transformer con Optimizador: {config['name']} (wd={config['wd']}) ---\")\n",
    "\n",
    "    backbone_swin = SwinV2FeatureExtractor().to(device)\n",
    "    model_swin = Model(backbone=backbone_swin, backbone_out_features=1024).to(device) # Swin-V2-B tiene 1024 features\n",
    "    optimizer_swin = config[\"optim\"](model_swin.parameters(), lr=LEARNING_RATE_SWIN, weight_decay=config[\"wd\"])\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"Época {epoch + 1}/{EPOCHS}\")\n",
    "        train_one_epoch(model_swin, train_loader_tl, optimizer_swin, device)\n",
    "        current_iou = evaluate(model_swin, val_loader_tl, device)\n",
    "\n",
    "        if current_iou > best_swin_iou:\n",
    "            best_swin_iou = current_iou\n",
    "            best_swin_model = copy.deepcopy(model_swin.state_dict())\n",
    "            print(f\"Nuevo mejor modelo Swin Transformer con IoU: {best_swin_iou:.4f}\")\n",
    "\n",
    "torch.save(best_swin_model, 'swin_transformer_best.pth')\n",
    "print(\"\\nMejor modelo Swin Transformer guardado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generación del Archivo de Submission\n",
    "\n",
    "Finalmente, cargamos el mejor modelo obtenido de todos los experimentos (el que haya alcanzado el mayor IoU en validación) y lo utilizamos para generar las predicciones sobre el conjunto de test. Las predicciones se guardan en un archivo `submission.csv` con el formato requerido por la competencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando el mejor modelo para la inferencia...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generando predicciones: 100%|██████████| 55/55 [00:01<00:00, 48.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Archivo 'submission.csv' generado con éxito.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filename</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>IMG_4861_mp4-50_jpg.rf.7173e37ed9f62f8939af82323289faf2.jpg</th>\n",
       "      <td>no-mask</td>\n",
       "      <td>158.032364</td>\n",
       "      <td>132.117340</td>\n",
       "      <td>420.171753</td>\n",
       "      <td>316.990112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video_CDC-YOUTUBE_mp4-58_jpg.rf.370d5f316397477da0ff4f44799b1da9.jpg</th>\n",
       "      <td>mask</td>\n",
       "      <td>184.373398</td>\n",
       "      <td>70.928772</td>\n",
       "      <td>301.979736</td>\n",
       "      <td>272.172791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video_CDC-YOUTUBE_mp4-57_jpg.rf.de4856b9a314980e4113335576f453a8.jpg</th>\n",
       "      <td>mask</td>\n",
       "      <td>253.181732</td>\n",
       "      <td>66.167816</td>\n",
       "      <td>386.809326</td>\n",
       "      <td>385.631744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IMG_3102_mp4-0_jpg.rf.6a18575fb4bf7f69cc9006b9a5f34e08.jpg</th>\n",
       "      <td>no-mask</td>\n",
       "      <td>281.951721</td>\n",
       "      <td>170.056580</td>\n",
       "      <td>693.483337</td>\n",
       "      <td>630.411255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IMG_3094_mp4-34_jpg.rf.11eecb9601680286dc8338d5e8b9acb2.jpg</th>\n",
       "      <td>no-mask</td>\n",
       "      <td>158.604919</td>\n",
       "      <td>256.652893</td>\n",
       "      <td>711.819397</td>\n",
       "      <td>630.828247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      class        xmin  \\\n",
       "filename                                                                  \n",
       "IMG_4861_mp4-50_jpg.rf.7173e37ed9f62f8939af8232...  no-mask  158.032364   \n",
       "video_CDC-YOUTUBE_mp4-58_jpg.rf.370d5f316397477...     mask  184.373398   \n",
       "video_CDC-YOUTUBE_mp4-57_jpg.rf.de4856b9a314980...     mask  253.181732   \n",
       "IMG_3102_mp4-0_jpg.rf.6a18575fb4bf7f69cc9006b9a...  no-mask  281.951721   \n",
       "IMG_3094_mp4-34_jpg.rf.11eecb9601680286dc8338d5...  no-mask  158.604919   \n",
       "\n",
       "                                                          ymin        xmax  \\\n",
       "filename                                                                     \n",
       "IMG_4861_mp4-50_jpg.rf.7173e37ed9f62f8939af8232...  132.117340  420.171753   \n",
       "video_CDC-YOUTUBE_mp4-58_jpg.rf.370d5f316397477...   70.928772  301.979736   \n",
       "video_CDC-YOUTUBE_mp4-57_jpg.rf.de4856b9a314980...   66.167816  386.809326   \n",
       "IMG_3102_mp4-0_jpg.rf.6a18575fb4bf7f69cc9006b9a...  170.056580  693.483337   \n",
       "IMG_3094_mp4-34_jpg.rf.11eecb9601680286dc8338d5...  256.652893  711.819397   \n",
       "\n",
       "                                                          ymax  \n",
       "filename                                                        \n",
       "IMG_4861_mp4-50_jpg.rf.7173e37ed9f62f8939af8232...  316.990112  \n",
       "video_CDC-YOUTUBE_mp4-58_jpg.rf.370d5f316397477...  272.172791  \n",
       "video_CDC-YOUTUBE_mp4-57_jpg.rf.de4856b9a314980...  385.631744  \n",
       "IMG_3102_mp4-0_jpg.rf.6a18575fb4bf7f69cc9006b9a...  630.411255  \n",
       "IMG_3094_mp4-34_jpg.rf.11eecb9601680286dc8338d5...  630.828247  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===============================================\n",
    "# GENERACIÓN DE SUBMISSION (CORREGIDA)\n",
    "# ===============================================\n",
    "\n",
    "test_df = pd.read_csv(osp.join(DATA_DIR, \"test.csv\"))\n",
    "\n",
    "test_transforms = A.Compose([\n",
    "    A.Resize(IMG_SIZE, IMG_SIZE)\n",
    "])\n",
    "\n",
    "test_dataset = MaskDataset(test_df, root_dir=IMG_DIR, transform=test_transforms, labeled=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "print(\"Cargando el mejor modelo para la inferencia...\")\n",
    "best_backbone = EffNetFeatureExtractor().to(device) # Cambiar si otro modelo fue el mejor\n",
    "best_model = Model(backbone=best_backbone, backbone_out_features=1280).to(device)\n",
    "best_model.load_state_dict(torch.load('efficientnet_best.pth'))\n",
    "best_model.eval()\n",
    "\n",
    "filenames, class_preds, xmins, ymins, xmaxs, ymaxs = [], [], [], [], [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(tqdm(test_loader, desc=\"Generando predicciones\")):\n",
    "        image = batch['image'].to(device)\n",
    "        preds = best_model(image)\n",
    "\n",
    "        class_id = torch.argmax(preds['class_id'], dim=1).cpu().item()\n",
    "        bbox = preds['bbox'].cpu().numpy()[0]\n",
    "\n",
    "        xmin = bbox[0] * w_real\n",
    "        ymin = bbox[1] * h_real\n",
    "        xmax = bbox[2] * w_real\n",
    "        ymax = bbox[3] * h_real\n",
    "\n",
    "        filenames.append(test_df.filename.iloc[i])\n",
    "        class_preds.append(id2obj[class_id])\n",
    "        xmins.append(xmin)\n",
    "        ymins.append(ymin)\n",
    "        xmaxs.append(xmax)\n",
    "        ymaxs.append(ymax)\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'filename': filenames,\n",
    "    'class': class_preds,\n",
    "    'xmin': xmins,\n",
    "    'ymin': ymins,\n",
    "    'xmax': xmaxs,\n",
    "    'ymax': ymaxs\n",
    "})\n",
    "\n",
    "submission_df = submission_df.set_index('filename')\n",
    "\n",
    "submission_df.to_csv('submission.csv')\n",
    "\n",
    "print(\"\\nArchivo 'submission.csv' generado con éxito.\")\n",
    "submission_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
